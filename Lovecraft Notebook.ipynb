{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f74d8143",
   "metadata": {},
   "source": [
    "Generation Cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b20e4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If running this cell gives you an error. Install torch, pandas and transformers using pip or conda.\n",
    "#It is recommended you use conda for this notebook.\n",
    "import torch\n",
    "import pandas as pd \n",
    "from transformers import Trainer, AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "\n",
    "#Set to \"CPU\" if your graphics card doesn't have enough VRAM.\n",
    "device = torch.device(\"cuda\")\n",
    "    \n",
    "#Generates outputs.\n",
    "def generate_story(prompt, max_length=512, min_length=512, temperature=0.7):\n",
    "    print(\"Generating: \" + prompt)\n",
    "    \n",
    "    generated = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).input_ids\n",
    "    sample_outputs = model.generate(generated.to(device), temperature=temperature, do_sample=True, num_return_sequences=5, max_length=max_length, min_length=min_length)\n",
    "    output_texts = []\n",
    "\n",
    "    for i, sample_output in enumerate(sample_outputs): \n",
    "        output_text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "        #print(output_text + \"\\n\")\n",
    "        output_texts.append(output_text)\n",
    "\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c8949b",
   "metadata": {},
   "source": [
    "Loads models. (Run This cell and the cell above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a426bcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a772c132924c169e0e330eb83319ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/976k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b28cf6295724664a723d1d1e70226f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6be901e097442685a5ee9c003baf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/548 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf7cbfff1c44c18927eadb367c8e7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/870 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, OPTForCausalLM\n",
    "\n",
    "#Don't change either of these.\n",
    "model_name = \"BearlyWorkingYT/OPT-125M-Lovecraft\"\n",
    "tokenizer_name = \"BearlyWorkingYT/OPT-125M-Lovecraft\"\n",
    "\n",
    "model = OPTForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_name, use_fast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8476ef40",
   "metadata": {},
   "source": [
    "Generates story from model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a8ff338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating: </s>Horror\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Horror was unleashed as the whole household saw the horror. Elwood hastened to the depositary box and began digging feverishly into the contents. My uncle shook his head, but kept on digging. When he was done, he said, all the bones and skulls of the deceased were resting on the boxes and in various stages of dismemberment. He buried the whole skeleton in a secret cellar beneath a cellar wall, and from the scattered bones which lay after the horror, was sure that the box had contained something which was not a corpse. He was very disconcerting, but very fortunately not evil. The other three were',\n",
       " 'Horror was unleashed, and in the daemoniac interval there was another which put an end to both of them. Elder things from outside had begun to attack the trees, and in a spirit of supreme fright the younger and the older ones were about to bolt away. It was the same with the nameless stonework of the cemetery, for beneath it lay a hellish basalt pool whose greyish surface was like some monstrous fungi. Only the older ones, of whom two were still missing, remembered what Thaddeus had said about a fungous burying-ground being impious and evil; and they looked furtively up',\n",
       " 'Horror for me seemed to lurk far within that final layer of mould and horror. What followed, I cannot tell; for it was a continuous, unverifiable experience, and there were times when I fancied I saw faint, half-visible shapes not quite like those which I had imagined. I felt that I was not dreaming or deluded; and yet the effect of these visions was almost too much to bear. Suddenly my pain, reeling from stark, utter despair, subsided into a state of tense agitation; and I began to drive madly, wildly, with a crash which sent me sprawling on the ground in',\n",
       " 'Horror was mounting upon the bewildered pair, as if some monstrous fate had beenfallen. Charles had seemed too shaken to be wise to call on his mother, and she may have well been frightened at his aspect as the trees began to sway in the breeze. All at once she heard a fumbling at the latch and saw that the portal was slowly swinging open again. A second later her cries were heard again, and this time she could hear the hinges creak as if through some door beyond her knowledge. All at once she saw that the new portal was indeed ajar, and hurried upstairs to find out more about her',\n",
       " 'Horror was mingled with terror, for this was a house in whose basement had been found a horror older than all man’s. The place had indeed been inhabited by a strange and long-dead servant, and strange cries had been heard at night. Detectives have questioned the living servants, but have found them all dead. And what, I half imagine, of the long-dead cat? The place had been almost a temple, with dark, roofless steeps, and abnormally wide windows. What hieroglyphics had ever caught the glance of poor Frank Marsh? The coffin—what was it that had']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, OPTForCausalLM\n",
    "\n",
    "#Edit this prompt to control generation.\n",
    "prompt = \"</s>Horror\"\n",
    "\n",
    "#Adjusted temperature to control randomness of generation.\n",
    "generate_story(prompt, max_length=128, min_length=64, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f396ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
